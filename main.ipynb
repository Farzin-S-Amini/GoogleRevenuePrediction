{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (90405, 54)\n",
      "False    89317\n",
      "True      1088\n",
      "Name: shops or not, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.99      0.99     17878\n",
      "       True       0.26      0.31      0.28       203\n",
      "\n",
      "avg / total       0.98      0.98      0.98     18081\n",
      "\n",
      "1653574003235440.5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_df(csv_path='./data/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    p=0.1\n",
    "    df = pd.read_csv(csv_path,\n",
    "                     converters={column: json.loads for column in JSON_COLUMNS},\n",
    "                     dtype={'fullVisitorId': 'str'}, nrows=nrows, # Important!!\n",
    "                      skiprows=lambda i: i > 0 and random.random() > p)\n",
    "\n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "train_df = load_df()\n",
    "pd.set_option('display.max_columns', None)\n",
    "# print(train_df.head())\n",
    "# shops_or_not=lambda x : x.train_df.totals.transactionRevenue > 0\n",
    "train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\n",
    "train_df['shops or not'] = train_df['totals.transactionRevenue'].values > 0\n",
    "# y_clf = (train_df['totals.transactionRevenue'].fillna(0) > 0).astype(np.uint8)\n",
    "print(pd.value_counts(train_df['shops or not']))\n",
    "# print(pd.value_counts(y_clf))\n",
    "\n",
    "def date_format(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['vis_date'] = pd.to_datetime(df['visitStartTime'])\n",
    "    df['sess_date_dow'] = df['vis_date'].dt.dayofweek\n",
    "    df['sess_date_hours'] = df['vis_date'].dt.hour\n",
    "    df['sess_date_dom'] = df['vis_date'].dt.day\n",
    "\n",
    "date_format(train_df)\n",
    "\n",
    "# excluded_features = [\n",
    "#     'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue',\n",
    "#     'visitId', 'visitStartTime', 'vis_date'\n",
    "# ]\n",
    "categorical_features = [\n",
    "    _f for _f in train_df.columns\n",
    "    if (train_df[_f].dtype == 'object')\n",
    "]\n",
    "\n",
    "#print(categorical_features)\n",
    "\n",
    "for f in categorical_features:\n",
    "    train_df[f], indexer = pd.factorize(train_df[f])\n",
    "\n",
    "A=train_df.fillna(0)\n",
    "X=A.drop('shops or not',axis=1)\n",
    "L=X.drop('date',axis=1)\n",
    "Z=L.drop('vis_date',axis=1)\n",
    "\n",
    "\n",
    "M=Z.drop('totals.transactionRevenue',axis=1)\n",
    "y=train_df['shops or not']\n",
    "\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(M, y, test_size=0.20, random_state=101)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "DecTreeModel = DecisionTreeClassifier()\n",
    "DecTreeModel.fit(X_train,y_train)\n",
    "\n",
    "predictions = DecTreeModel.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#accuracy = cross_val_score(DecTreeModel, M, y, cv=5,scoring='accuracy')\n",
    "#print('Accuracy : ', np.mean(accuracy))\n",
    "#recall = cross_val_score(DecTreeModel, M, y, cv=5,scoring='recall')\n",
    "##print(scores_final)\n",
    "#print('Precision : ', np.mean(recall))\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y1 = train_df[\"totals.transactionRevenue\"].fillna(0)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(M, y1, test_size=0.20, random_state=101)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train1)\n",
    "#X_train1 = scaler.transform(X_train1)\n",
    "#X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "DecTreeReg = DecisionTreeRegressor()\n",
    "DecTreeReg.fit(X_train1,y_train1)\n",
    "\n",
    "predictions1 = DecTreeReg.predict(X_test1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test1, predictions1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088, 56)\n",
      "1.1633981804633026e+17\n",
      "42346      1550000.0\n",
      "81927    139000000.0\n",
      "7737      69150000.0\n",
      "15016     59990000.0\n",
      "68565     79990000.0\n",
      "10744     25820000.0\n",
      "13546     16990000.0\n",
      "62994    101940000.0\n",
      "83271     44270000.0\n",
      "54904     72270000.0\n",
      "46799     44370000.0\n",
      "63001    194930000.0\n",
      "36159     11190000.0\n",
      "36154     79990000.0\n",
      "52900     57970000.0\n",
      "72188    359930000.0\n",
      "89107    195360000.0\n",
      "10621     71700000.0\n",
      "31834    491250000.0\n",
      "75559     27190000.0\n",
      "76769     19990000.0\n",
      "73448     47970000.0\n",
      "41146     30390000.0\n",
      "15023     92410000.0\n",
      "55498     32460000.0\n",
      "30265    368900000.0\n",
      "30976    121450000.0\n",
      "53829    167400000.0\n",
      "17862     47880000.0\n",
      "49250     44790000.0\n",
      "            ...     \n",
      "80691    404940000.0\n",
      "87651     16990000.0\n",
      "45713     62150000.0\n",
      "87653     53980000.0\n",
      "82862     38160000.0\n",
      "85792     60980000.0\n",
      "32095     27160000.0\n",
      "41690     18990000.0\n",
      "73461     24990000.0\n",
      "5708      47570000.0\n",
      "58971     19190000.0\n",
      "46536     33590000.0\n",
      "60912     18990000.0\n",
      "6979      17590000.0\n",
      "76350    156820000.0\n",
      "8987      15190000.0\n",
      "19637     13590000.0\n",
      "20775     59990000.0\n",
      "18868     52060000.0\n",
      "47318     18990000.0\n",
      "10236     50000000.0\n",
      "77370    191550000.0\n",
      "4408      91140000.0\n",
      "84313    167680000.0\n",
      "15213     30380000.0\n",
      "17204     15190000.0\n",
      "55495     57960000.0\n",
      "32898     41990000.0\n",
      "90         5150000.0\n",
      "85044     46370000.0\n",
      "Name: totals.transactionRevenue, Length: 218, dtype: float64 [3.08800e+07 5.19900e+07 1.40000e+07 1.62300e+07 4.15900e+07 1.89900e+07\n",
      " 9.11400e+07 7.99800e+07 1.67800e+07 2.27800e+07 1.91900e+07 2.55100e+08\n",
      " 7.98000e+07 1.33950e+08 8.95500e+07 1.11960e+08 3.46900e+07 3.19700e+07\n",
      " 2.87800e+07 1.35900e+07 3.15490e+08 1.11390e+08 1.51900e+07 6.17900e+07\n",
      " 1.49600e+07 5.86600e+07 7.19400e+07 5.08300e+07 4.87800e+08 9.91700e+07\n",
      " 2.95800e+07 2.29900e+07 1.10380e+08 1.35900e+07 2.27100e+07 4.19850e+08\n",
      " 1.59800e+07 8.79200e+07 1.89900e+07 4.47900e+07 2.71900e+07 1.29900e+07\n",
      " 3.89700e+07 4.39500e+07 3.03900e+07 1.11980e+08 1.62800e+07 1.43700e+08\n",
      " 9.09800e+07 6.99800e+08 1.11800e+08 8.57800e+07 2.39880e+08 2.24000e+08\n",
      " 3.15490e+08 1.35070e+09 6.17900e+07 2.71900e+07 7.99000e+06 7.34100e+07\n",
      " 1.47980e+08 2.67200e+08 1.09900e+07 2.67100e+07 3.92300e+07 3.14900e+07\n",
      " 7.34100e+07 8.95500e+07 3.87770e+08 5.79700e+07 1.15376e+09 1.99900e+07\n",
      " 7.99900e+07 1.77550e+08 3.46900e+07 2.87800e+07 3.75700e+07 1.91980e+08\n",
      " 4.39800e+07 4.28500e+07 3.99900e+07 7.28340e+08 3.83800e+07 2.39900e+07\n",
      " 1.83980e+08 1.16970e+08 3.35900e+07 3.87770e+08 8.15000e+07 1.49500e+07\n",
      " 3.13530e+08 1.39800e+07 7.67600e+07 3.89700e+07 1.83800e+07 1.99900e+07\n",
      " 1.40000e+07 3.26600e+07 1.11390e+08 5.31900e+07 2.64630e+08 8.40000e+06\n",
      " 6.99800e+08 1.40000e+07 1.03180e+08 2.83530e+08 1.66970e+08 3.19750e+08\n",
      " 1.19800e+07 6.55700e+07 1.19800e+08 6.30400e+07 3.99900e+07 1.40560e+08\n",
      " 7.28340e+08 1.54980e+08 1.09900e+07 2.79370e+08 3.06800e+08 7.99000e+06\n",
      " 9.95680e+08 5.73400e+07 9.97000e+06 1.26980e+08 5.19900e+07 1.97540e+08\n",
      " 2.94000e+08 2.68420e+08 2.68740e+09 1.18960e+08 5.36980e+08 3.11400e+07\n",
      " 1.19130e+08 1.67150e+08 1.29970e+08 1.00000e+08 5.20200e+07 7.28340e+08\n",
      " 2.71900e+07 4.19900e+07 1.35900e+07 1.99900e+07 1.66320e+08 3.36800e+07\n",
      " 5.59900e+07 1.32900e+07 8.20350e+08 3.35900e+07 7.59700e+07 1.10770e+08\n",
      " 7.71900e+07 2.39880e+08 2.19900e+07 1.99900e+07 2.71900e+07 5.62000e+07\n",
      " 6.20310e+08 6.80300e+07 6.94200e+07 1.14960e+08 7.34100e+07 3.51800e+07\n",
      " 1.63500e+07 9.92500e+07 2.67200e+08 1.09990e+08 3.59140e+08 1.40000e+07\n",
      " 1.33950e+08 2.39900e+07 1.89800e+07 3.96300e+07 5.19900e+07 3.89700e+07\n",
      " 5.20700e+07 1.47036e+09 1.99900e+07 8.57800e+07 8.39000e+06 5.82270e+08\n",
      " 1.40560e+08 2.56500e+07 4.98800e+07 1.89900e+07 1.07880e+08 2.71900e+07\n",
      " 7.30300e+07 8.49500e+07 4.47900e+07 2.19300e+07 1.63500e+07 8.62650e+08\n",
      " 1.14960e+08 1.69900e+07 2.63800e+07 9.91700e+07 6.21000e+07 7.98000e+06\n",
      " 3.91900e+07 2.71900e+07 1.35800e+08 4.47900e+07 9.19400e+07 4.47900e+07\n",
      " 6.48000e+07 3.59800e+07 3.91860e+08 1.47980e+08 4.89900e+07 1.69610e+08\n",
      " 7.59100e+07 1.99900e+07 5.19900e+07 3.47700e+07 9.72400e+07 1.35900e+07\n",
      " 3.05470e+08 6.39750e+08]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_Reg=Z.loc[Z['totals.transactionRevenue']>0]\n",
    "Y_Reg=X_Reg['totals.transactionRevenue']\n",
    "X_Reg1=X_Reg.drop('totals.transactionRevenue',axis=1)\n",
    "\n",
    "\n",
    "print(X_Reg.shape)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_Reg1, Y_Reg, test_size=0.20)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "X_train1 = scaler.transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "DecTreeReg = DecisionTreeRegressor()\n",
    "DecTreeReg.fit(X_train1,y_train1)\n",
    "\n",
    "predictions1 = DecTreeReg.predict(X_test1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test1, predictions1))\n",
    "print(y_test1,predictions1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
